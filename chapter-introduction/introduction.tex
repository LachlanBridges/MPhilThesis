%!TEX root = ../thesis.tex

The study of animal movement is an incredibly broad topic, spanning multiple disciplines, with many unanswered questions. Results from studying the movement behaviour of animals have found applications in a number of different areas, and not always in fields related to animals.

Animals move for a seemingly endless number of reasons. Usually, they move in order to find food to eat, or a partner to mate with, but other reasons exist. Sheep begin running when they see other sheep running. They may also move in order to escape the clutches of a pursuing predator. 
Some animals move for fun, like dolphins playing games together.
Regardless of the true reasons for why an animal moves the way it does, which we may never know, the reproductive fitness of an animal is certainly affected by how it decides to move.

Natural selection should imply that animals evolve to move in a way that improves their reproductive fitness, whether they know it or not. 
This is the key reasoning that optimal foraging theory is built upon. 
Since the ability to forage for food is a good proxy for an animal's overall reproductive fitness, it is hypothesised that the optimal foraging strategy, in theory, should be the strategy used in practice.

Traditionally, animal foraging theory has been a branch of ecology, and has investigated the effect of qualitative decision rules, such as the choice of diet \cite{Raubenheimer_2018}. 
More recently, animal foraging theory has been investigated using a more quantitative approach, generally employing stochastic processes to model animal movement.  Stochastic optimal foraging theory, as it is sometimes referred to, is the field of study that investigates the optimal search strategy for a general forager which lacks complete information about its current environment, and does not have any memory capabilities. Stochastic optimal foraging theory complements the study of ordinary optimal foraging theory, in which the forager makes decisions based on complete information about its environment \cite{Bartumeus_2013}. In reality, animals fall in between the two, having some, though not complete, information about the environment.

In its most general sense, the study of animal foraging is interested in how different movement patterns can affect the frequency of biological encounters. An animal searching for food should aim to maximise the number of biological encounters, whereas an animal fleeing a predator should aim to minimise the number of encounters. For this reason, many of the models built with animals in mind are still valid for other things such as micro-organisms \cite{Benichou_2007}, genetic material \cite{Hoyle_2007}, and even swarm robots \cite{Sahin_2005}. Because of this, results originally found when investigating animals have been used to investigate how pollen diffuses \cite{Shaw_2006}, to program swarm robots to move efficiently \cite{Sahin_2005}, to design fisheries \cite{Richard_2018}, and have even been used in medicine \cite{Codling_2008}.

One of the earliest papers in stochastic optimal foraging theory was published in 1995 \cite{Cole_1995}, and showed that the distance of relocations for a type of fruitfly had a heavy-tailed distribution. 
There is some discrepancy over the exact definition of a heavy-tailed distribution, although in the animal foraging literature it is consistently used to mean not having finite variance, and we will use this definition going forward. This means that there is a reasonable probability of very large values occurring. In the context of the distance of animals relocating, this means that there are some instances of animals making very large relocations. Search strategies of this kind are known as L\'{e}vy flights, and have been an important area of research throughout the topic of animal foraging.

There is a common analogy often used \cite{Viswanathan_2009} to give an intuitive explanation as to why L\'{e}vy flight searches may be more efficient. Anyone that has ever lost something in their house has likely performed a search that resembles a L\'{e}vy flight. Imagine you are about to leave the house but you cannot find your car keys. You would search the room you are in, making small relocations around the room, while intensively searching in various places. After some time, you may realise that you left your keys in the kitchen. You run to the kitchen, which is a large relocation, before beginning your intensive search again. This scenario somewhat resembles a L\'{e}vy flight, with large steps occurring each time you change rooms, making the distribution of steps heavy-tailed. A random walk with light-tailed distribution of steps would instead take small steps throughout the whole search, including as you change rooms, meaning you would spend as much time searching the hallway between rooms as the rooms themselves. This type of search would correspond to something known as Brownian motion. 

Considering the above example, the efficiency of a L\'{e}vy flight over a Brownian motion seems fairly intuitive, not just for finding car keys, but for searching in general. This leads into one of the big advantages of stochastic optimal foraging theory over traditional foraging theory. By considering a general forager that is fully unaware of its surrounding, we are able to find results that may apply to any animal, or even any non-animal searcher, rather than finding results that only apply to a specific environment. For example, the L\'{e}vy flight may be an inherently better search strategy than a Brownian motion in many different scenarios.

A paper in 1999 \cite{Viswanathan_1999} devised a theoretical model to investigate the optimal search strategy for a forager. The strategies considered were random walks with steps drawn from a power-law distribution. Depending on the parameter $\mu$ of the power-law distribution, the steps may or may not be heavy-tailed, meaning qualitatively different strategies may occur with simply a change in the value of $\mu$. Thanks to this property, the power-law distribution has been used very frequently throughout the stochastic optimal foraging theory literature. The theoretical model allowed for two different scenarios: destructive and non-destructive foraging, under which the food once located is, or is not, destroyed. The optimal strategy for destructive foraging was found to occur when $\mu \to 1$, which corresponds to the forager selecting a very large step-size, meaning it will travel in a straight line, with no changes in direction until it reaches food. For non-destructive foraging, the optimal strategy was to use $\mu \approx 2$, which corresponds to a L\'{e}vy flight search strategy.

After the first two papers that found empirical evidence for L\'{e}vy flights in animal movements \cite{Cole_1995,Viswanathan_1996}, many other papers were published, mostly using the same methodology, but investigating different animals. Evidence of L\'{e}vy flights was found for almost all of the animals investigated, included spider-monkeys, fish, and even human hunter-gatherers. However, various papers (\cite{Benhamou_1989,Edwards_2011}, etc) have disputed the empirical evidence of L\'{e}vy flights, criticizing some of the methods used in other papers, as well as revisiting earlier results using larger datasets.


Many other theoretical papers also built upon the original theoretical model \cite{Viswanathan_1999}. Various extensions looked at including foraging for targets that are moving \cite{Bartumeus_2002}, foraging for targets in higher dimensions \cite{Santos_2005}, foraging for targets that are hidden while the forager is moving too fast \cite{Benichou_2005}, and targets with a delay before they can be revisited again \cite{Raposo_2003}.

More recently, a new type of strategy has been investigated, referred to as a giving-up time strategy, which involves switching between two different search modes. Initially a forager begins performing an intensive search according to a Brownian motion before giving up and performing ballistic motion, which corresponds to walking in a straight line, until food is located. These search strategies have been shown to outperform any kind of non-switching strategy, including the L\'{e}vy flight strategy, which was once thought to be the theoretical optimal. Various results have been found for these strategies, such as the optimal giving up time \cite{Plank_2008}. Others have also investigated a fixed giving-up time and found the optimal strategy to use after giving up, rather than just a ballistic motion. There is, as yet, no paper that has optimised over both the extensive strategy and the giving-up time.



For a long period of time, most of the stochastic foraging literature revolved around L\'{e}vy flights, since these were thought to be optimal. Once giving-up time and other switching strategies were considered, the focus then turned to investigating these. However, currently only strategies that switch between two different strategies have been looked into, with no investigation into switching between three or more modes. Generalising the switching strategies to more than two modes is a primary aim of this thesis.

We generalise the idea of a switching search strategy by considering Markov-modulated random walk strategies. A Markov-modulated random walk is a random walk, with the distribution of the steps of the random walk changing depending on the current state of some Markov chain. This effectively means that the forager switches between multiple different random walk search strategies, according to a Markov chain. Determining an analytic expression for the efficiency of a Markov-modulated random walk strategy, solving it numerically, and investigating the results forms the bulk of this thesis, from \cref{sec:1Dmodel,sec:1d_discrete,sec:1d_results}.


In \cref{sec:background}, we discuss some of the background required to understand the rest of the thesis. We outline some useful theorems that we will need, along with the definitions and results required to understand them. We outline some of the key terms used in the literature, and discuss other variations on them, in order to keep consistency when discussing the literature review. \Cref{sec:background} concludes with a literature review, in which we discuss some of the important papers in stochastic foraging, as well as papers that devise extensions to the basic model. We discuss and interpret some of the key results found, including the optimal strategies for various models, as well as the conclusions of the composite strategies.

\Cref{sec:1Dmodel} begins with an investigation into a somewhat recent model for animal foraging in one dimension by Bartumeus \etal \cite{Bartumeus_2013}. The authors were able to derive an analytic expression for the efficiency of a forager searching using a random walk with any choice of step-length distribution. We prove some key results from this paper for which proofs were not included. We then extend the model to allow for Markov-modulated random walk search strategies, with any number of states. This means we allow for a forager to switch between any number of different search strategies according to a discrete-time Markov chain. We derive an analytic expression for the efficiency of any Markov-modulated random walk strategy, as well as the expected number of steps in each state of a strategy. The results of this \lcnamecref{sec:1Dmodel} may be considered the most important results of this thesis.

In \cref{sec:1d_discrete} we take our model from \Cref{sec:1Dmodel} and discretise the search space, allowing us to find numerical solutions. We derive discretised approximations of our results from \Cref{sec:1d_discrete}. This \lcnamecref{sec:1d_discrete} also helps to further demonstrate some of the difficulties found throughout our derivation of the Markov-modulated random walk results in \Cref{sec:1Dmodel}.

In \Cref{sec:1d_results} we make use of the results found throughout \Cref{sec:1Dmodel,sec:1d_discrete} to recover some results from the literature as well as find some new results. We discuss how various strategies throughout the literature can be considered as a specific case of a Markov-modulated random walk, with certain parameters. We show specifically how we can recover unmodulated random walk strategies, giving-up time strategies, some vision-switching strategies, and show that our results match existing results. Finally, we optimise over all of the parameters of our Markov-modulated random walk, finding new results for optimal search strategies.

\Cref{sec:2dmodel} is mostly independent of the previous chapters, in which we devise a simple two-dimensional model in order to obtain some analytic results for the optimal search strategy. We consider food targets that are distributed according to a spatial Poisson process, and thus the probability of finding food is proportional to the amount of space that a forager searches. We initially consider a model in which targets may be found upon reexploring a previously explored area, which we refer to as the zeroth-order approximation. We discuss the first-order model, in which area that was searched more than one step ago may contain targets. Analytic results for the first-order model require a discussion of the geometry of the overlap between consecutive steps, and this eventually results in a model that is too hard to solve. We perform numerical simulations of the zeroth-order, first-order, and infinite-order model, which is the exact model, and are able to show that the first-order model does not provide a very accurate approximation for the infinite-order model anyway. Thus, this \lcnamecref{sec:2dmodel} provides some basic results for two-dimensional models, while also showing some of the difficulties that arise when trying to obtain analytic results in two dimensions.

Finally, in \cref{sec:conclusion}, we discuss the significance of our results, and examine which results match and which contradict the existing results. We also discuss some possible avenues of future research that have been opened up thanks to this research, as well as possible extensions to our models.







